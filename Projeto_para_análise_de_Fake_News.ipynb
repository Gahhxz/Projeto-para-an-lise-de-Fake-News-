{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gahhxz/Projeto-para-an-lise-de-Fake-News-/blob/main/Projeto_para_an%C3%A1lise_de_Fake_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "UCCbECexLk_h"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "bV4w0H5TLk5g"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informação mais recente que seu conhecimento\n",
        "\n",
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "# Perguntar pro modelo quando é a próxima imersão de IA ###############################################\n",
        "resposta = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Lula recusou vacina japonesa contra a dengue para esperar imunizante nacional',\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {resposta.text}\")) # Changed 'response' to 'resposta'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Y9cBAz02xZt9",
        "outputId": "ab9bd573-a050-4815-a693-e992b29845ff"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n Em abril de 2024, o governo brasileiro, sob a gestão do presidente Lula, optou por não adquirir a vacina Qdenga contra a dengue, produzida pelo laboratório japonês Takeda Pharma, para o Sistema Único de Saúde (SUS). A decisão foi tomada com o argumento de que o governo priorizaria o desenvolvimento e a produção de uma vacina nacional contra a dengue, em parceria com o Instituto Butantan.\n\n**Justificativas do governo:**\n\n*   **Priorização da produção nacional:** O governo expressou o desejo de fortalecer a indústria farmacêutica nacional e reduzir a dependência de importações. O desenvolvimento de uma vacina brasileira contra a dengue seria um passo importante nesse sentido.\n*   **Custos e disponibilidade:** A vacina Qdenga tem um custo relativamente alto e a disponibilidade em larga escala para atender toda a população brasileira seria um desafio.\n*   **Eficácia e segurança:** Embora a Qdenga seja considerada segura e eficaz, o governo brasileiro avaliou que a vacina em desenvolvimento pelo Instituto Butantan poderia ter um perfil de eficácia e segurança mais adequado às necessidades do país.\n\n**Contrapontos e críticas:**\n\n*   **Urgência da situação:** O Brasil enfrenta um grave problema de saúde pública com a dengue, com um aumento significativo no número de casos e óbitos. A não aquisição imediata da Qdenga gerou críticas de especialistas e da oposição, que argumentaram que a vacina poderia ajudar a controlar a epidemia.\n*   **Atraso na produção nacional:** O desenvolvimento e a produção de uma vacina nacional levam tempo, e não há garantia de que estará disponível em curto prazo. A demora em oferecer uma vacina à população pode ter consequências negativas para a saúde pública.\n*   **Disponibilidade de recursos:** Alguns críticos argumentaram que o governo poderia adquirir a Qdenga em paralelo ao desenvolvimento da vacina nacional, utilizando recursos adicionais para acelerar o processo e proteger a população.\n\n**Situação atual:**\n\nO governo brasileiro segue investindo no desenvolvimento da vacina contra a dengue pelo Instituto Butantan, que está em fase de testes clínicos. A expectativa é que a vacina esteja disponível para a população nos próximos anos. Enquanto isso, o governo tem adotado outras medidas para combater a dengue, como o controle do mosquito Aedes aegypti e a conscientização da população sobre a prevenção da doença."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content( model=MODEL_ID, contents='Lula recusou vacina japonesa contra a dengue para esperar imunizante nacional', config={\"tools\": [{\"google_search\": {}}]} )"
      ],
      "metadata": {
        "id": "lc2JPA92xbnp"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a busca\n",
        "print(f\"Busca realizada: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
        "# Exibe as URLs nas quais ele se baseou\n",
        "print(f\"Páginas utilizadas na resposta: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
        "print()\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "6Cg0KNJGMgC5",
        "outputId": "e0e46457-6dc4-4126-df69-7cc96e7a1561"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Busca realizada: ['Vacina dengue Brasil', 'Lula recusou vacina japonesa da dengue para esperar imunizante nacional']\n",
            "Páginas utilizadas na resposta: youtube.com, afp.com, terra.com.br, cofen.gov.br, saude.gov.br, butantan.gov.br, www.gov.br\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF8s6wO57aI8r8R-7_w6eG9uk6VLZNqzJFScFHT37Yhn-Hlsr1tHx67KTMQI7vOv6rkFFOwNWasI7j_Yr3kDedVKvMxuTxV38QrNUlkGhlOCB36TuUDBk9_t3w-jWIBUvpj_EH3YpBQk5cO4-tPNaFFbiNDi7vITWv7jUO-bN_FPQ_nhAIs3l8OGtmCuCqHnZ1WYfwDPiId\">Vacina dengue Brasil</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG9UOmDZ-qI_Hym6tV09p-a1k_gehDFuIKxZmN5Uz_YKntIQPdDWQVlCL7WqQuFWBSxJIYVAtCraTHelh956eJPOkNVlA5sjNGSO6i_tWdJXC9DD0E01S2mtbYwxY3YSH2bEYqtfDh4rkExlzTZFVG58hthb_3UYasSSPo9Qu7YNfzZ1fdnujHPT1GTaTAlk0axaSKp35Iry4QvYg7NwgoTcI4VmGaCJrqkfmhBf6ype2-BHQurs3SbdbTWhTtnlrn7r4vyeiVi3Go9aA==\">Lula recusou vacina japonesa da dengue para esperar imunizante nacional</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework de agentes do Google ################################################\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "id": "a1eRPalxEnj7"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q agentforge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1K7JVAc4wHV",
        "outputId": "0c03d029-7cb2-456d-d007-fd2231b10d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.9/191.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.2/606.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for browse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "aePV2bdfDeoW"
      },
      "outputs": [],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types  # Para criar conteúdos (Content e Part)\n",
        "from datetime import date\n",
        "import textwrap # Para formatar melhor a saída de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "import requests # Para fazer requisições HTTP\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    # Cria um serviço de sessão em memória\n",
        "    session_service = InMemorySessionService()\n",
        "    # Cria uma nova sessão (você pode personalizar os IDs conforme necessário)\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    # Cria um Runner para o agente\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Cria o conteúdo da mensagem de entrada\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "    # Itera assincronamente pelos eventos retornados durante a execução do agente\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "_xP4lWhsS5ko"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "8dosiodaxfFR"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "# --- Agente 1: Buscador --- #\n",
        "#######################################################\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError # Import HttpError\n",
        "def agente_buscador(topico, data_de_hoje):\n",
        "    \"\"\" Agente que busca informações no Google.\n",
        "    Instruções:\n",
        "    Você é um assistente de pesquisa. A sua tarefa é usar a ferramenta de busca do Google para recuperar as últimas notícias e vídeos relevantes sobre o tópico abaixo.\n",
        "    no mínimo 5 notícias contras e 5 notícias a favor, se tiver e no mínimo 3 vídeo a favor e 3 vídeo contra, se também tiver.\n",
        "    Foque em encontrar notícias e vídeos de fontes confiáveis e com diferentes perspectivas (a favor e contra).\n",
        "    \"\"\"\n",
        "\n",
        "    # Substitua pelas suas credenciais\n",
        "    API_KEY = \"AIzaSyDLCVSDWldjkDf34UgYhoavRETOioE3el4\" # Replace with your actual API Key\n",
        "    SEARCH_ENGINE_ID = \"23b45170bbc514939\" # Replace with your actual Search Engine ID\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=API_KEY)\n",
        "\n",
        "    resultados_noticias = []\n",
        "    resultados_videos_favor = []\n",
        "    resultados_videos_contra = []\n",
        "\n",
        "    try:\n",
        "        # Busca por notícias\n",
        "        resposta_noticias = service.cse().list(\n",
        "            q=topico,\n",
        "            cx=SEARCH_ENGINE_ID,\n",
        "        ).execute()\n",
        "        if 'items' in resposta_noticias:\n",
        "            for item in resposta_noticias['items']:\n",
        "                titulo = item['title']\n",
        "                link = item['link']\n",
        "                resultados_noticias.append({\"titulo\": titulo, \"link\": link})\n",
        "\n",
        "        # Busca por vídeos a favor\n",
        "        resposta_videos_favor = service.cse().list(\n",
        "            q=topico + \" vídeos a favor\",\n",
        "            cx=SEARCH_ENGINE_ID,\n",
        "        ).execute()\n",
        "        if 'items' in resposta_videos_favor:\n",
        "            for item in resposta_videos_favor['items']:\n",
        "                titulo = item['title']\n",
        "                link = item['link']\n",
        "                resultados_videos_favor.append({\"titulo\": titulo, \"link\": link})\n",
        "\n",
        "        # Busca por vídeos contra\n",
        "        resposta_videos_contra = service.cse().list(\n",
        "            q=topico + \" vídeos contra\",\n",
        "            cx=SEARCH_ENGINE_ID,\n",
        "        ).execute()\n",
        "        if 'items' in resposta_videos_contra:\n",
        "            for item in resposta_videos_contra['items']:\n",
        "                titulo = item['title']\n",
        "                link = item['link']\n",
        "                resultados_videos_contra.append({\"titulo\": titulo, \"link\": link})\n",
        "\n",
        "    except HttpError as e:\n",
        "        print(f\"Erro ao acessar a API do Google Custom Search: {e}\")\n",
        "        print(\"Possível causa: Quota diária excedida. Por favor, espere o limite ser resetado ou verifique sua configuração de faturamento.\")\n",
        "        # Return empty lists or raise the exception depending on desired behavior\n",
        "        return {\n",
        "            \"noticias\": [],\n",
        "            \"videos_favor\": [],\n",
        "            \"videos_contra\": [],\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro inesperado durante a busca: {e}\")\n",
        "        return {\n",
        "            \"noticias\": [],\n",
        "            \"videos_favor\": [],\n",
        "            \"videos_contra\": [],\n",
        "        }\n",
        "\n",
        "    # Retorna os resultados\n",
        "    return {\n",
        "        \"noticias\": resultados_noticias,\n",
        "        \"videos_favor\": resultados_videos_favor,\n",
        "        \"videos_contra\": resultados_videos_contra,\n",
        "    }"
      ],
      "metadata": {
        "id": "o8bqIfi_DyH8"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "# --- Agente 2: Detector de sátiras --- #\n",
        "#######################################################\n",
        "def agente_deteccao_satira(titulo, conteudo, url): \"\"\" Detecta se uma notícia é uma sátira ou paródia. Args: titulo: O título da notícia. conteudo: O conteúdo da notícia. url: A URL da notícia. Returns: True se a notícia for uma sátira, False caso contrário. \"\"\" # 1. Análise de palavras-chave palavras_chave_satira = [\"paródia\", \"sátira\", \"humor\", \"irônico\", \"absurdo\", \"fictício\"] titulo_minusculo = titulo.lower() conteudo_minusculo = conteudo.lower() contagem_palavras_chave = sum([1 for palavra in palavras_chave_satira if palavra in titulo_minusculo or palavra in conteudo_minusculo]) # 2. Análise de estilo (exagero, ironia, sarcasmo) exagero = False ironia_sarcasmo = False # Detecção de exagero (exemplo simplificado) if \"explodiu em pedaços\" in conteudo_minusculo or \"viajou mais rápido que a luz\" in conteudo_minusculo: exagero = True # Detecção de ironia/sarcasmo (requer técnicas mais avançadas) # ... # 3. Verificação de fontes fontes_satiricas = [\"theonion.com\", \"sensacionalista.com.br\"] url_minusculo = url.lower() fonte_satirica = any([fonte in url_minusculo for fonte in fontes_satiricas]) # Combinação dos resultados if contagem_palavras_chave >= 2 or exagero or fonte_satirica: return True # Provavelmente sátira else: return False # Provavelmente não é sátira"
      ],
      "metadata": {
        "id": "267SyeqUBTlC"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#--- Agente 3: Avaliação de Fontes (Refinado e com Gemini Search) ---\n",
        "#######################################################\n",
        "from google.genai import types # Ensure types is imported for Content and Part\n",
        "\n",
        "def agente_avaliacao_fontes(url):\n",
        "    \"\"\"\n",
        "    Avalia a confiabilidade de uma fonte de notícia usando Gemini Search.\n",
        "\n",
        "    Args:\n",
        "        url: A URL da fonte de notícia.\n",
        "\n",
        "    Returns:\n",
        "        Una pontuação de confiabilidade entre 0 e 1 (quanto maior, mais confiável),\n",
        "        baseada na análise do Gemini Search.\n",
        "    \"\"\"\n",
        "    # Converta o URL para minúsculas\n",
        "    url_lower = url.lower()\n",
        "\n",
        "    # Use o cliente Gemini configurado anteriormente (client)\n",
        "    global client # Assumes 'client' was initialized globally or in a parent scope\n",
        "    global MODEL_ID # Assumes 'MODEL_ID' was initialized globally or in a parent scope\n",
        "\n",
        "    # Construct a query for Gemini to research the source's reliability\n",
        "    search_query = f\"Avalie a confiabilidade da fonte de notícias do site: {url_lower}. Esta fonte costuma publicar notícias verdadeiras, falsas ou uma mistura de ambas? Mencione exemplos recentes se possível.\"\n",
        "\n",
        "    # Use Gemini with the Google Search tool\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=search_query,\n",
        "            config={\"tools\": [{\"google_search\": {}}]}\n",
        "        )\n",
        "\n",
        "        # Check if the response contains text\n",
        "        if response and response.text:\n",
        "            # Analyze Gemini's response to determine reliability\n",
        "            # This is a simplified interpretation based on keywords.\n",
        "            # A more robust implementation might require a separate agent\n",
        "            # or more sophisticated NLP analysis of the response text.\n",
        "            response_text_lower = response.text.lower()\n",
        "            confiabilidade = 0.5 # Default if unsure\n",
        "\n",
        "            # Simple keyword analysis of Gemini's response\n",
        "            if \"altamente confiável\" in response_text_lower or \"geralmente precisa\" in response_text_lower or \"publica informações verificadas\" in response_text_lower:\n",
        "                confiabilidade = 0.9\n",
        "            elif \"fonte satírica\" in response_text_lower or \"fake news\" in response_text_lower or \"desinformação\" in response_text_lower or \"informações falsas\" in response_text_lower:\n",
        "                confiabilidade = 0.1\n",
        "            elif \"mistura de verdade e falsidade\" in response_text_lower or \"viés notável\" in response_text_lower or \"ocasionalmente imprecisa\" in response_text_lower:\n",
        "                confiabilidade = 0.4 # Lower score for mixed or biased sources\n",
        "            # Keep default 0.5 if response is neutral or unclear\n",
        "\n",
        "            print(f\"Avaliação de Gemini Search para {url}: {response.text[:200]}...\") # Print snippet of Gemini's response\n",
        "            return confiabilidade\n",
        "\n",
        "        else:\n",
        "            print(f\"Gemini Search não retornou texto para {url}.\")\n",
        "            return 0.3 # Return a lower score if search is unsuccessful or no text is returned\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ocorreu um erro ao usar Gemini Search para avaliar {url}: {e}\")\n",
        "        return 0.3 # Return a lower score in case of errors\n",
        "\n",
        "# \"\"\" Avalia a confiabilidade de uma fonte de notícia. Args: url: A URL da fonte de notícia. Returns: Uma pontuação de confiabilidade entre 0 e 1 (quanto maior, mais confiável). \"\"\"\n",
        "# # Implementar lógica para avaliar a confiabilidade da fonte\n",
        "# # Com base em critérios como reputação, transparência e qualidade editorial"
      ],
      "metadata": {
        "id": "5ebnxQGVCJZl"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 4: Analista (Melhorado - Corrigido) --- #\n",
        "################################################\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Adicionamos o novo parâmetro 'confiabilidades_existente'\n",
        "def agente_analisador(resultados, data_de_hoje, confiabilidades_existentes):\n",
        "    \"\"\"\n",
        "    Agente que analisa notícias e vídeos, avalia fontes e determina a veracidade.\n",
        "\n",
        "    Args:\n",
        "        resultados (dict): Um dicionário contendo listas de notícias e vídeos.\n",
        "                           Esperado formato: {\"noticias\": [...], \"videos\": [...]}.\n",
        "        data_de_hoje (str): A data atual no formato DD/MM/YYYY.\n",
        "        confiabilidades_existentes (dict): Dicionário com URLs como chaves e pontuações\n",
        "                                           de confiabilidade como valores, pré-calculadas\n",
        "                                           pelo Agente 3.\n",
        "\n",
        "    Returns:\n",
        "        dict: Um dicionário contendo a análise detalhada e as pontuações de confiabilidade.\n",
        "              Formato: {\"analise\": str, \"confiabilidades\": dict}.\n",
        "    \"\"\"\n",
        "    analisador = Agent(\n",
        "        name=\"agente_analisador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é um especialista em análise de notícias e verificação de fatos.\n",
        "        Sua tarefa é analisar cuidadosamente as notícias e vídeos fornecidos,\n",
        "        avaliar a credibilidade das fontes (usando as pontuações fornecidas) e, com base em todas as evidências,\n",
        "        fornecer uma análise detalhada e uma determinação clara sobre a veracidade da informação.\n",
        "\n",
        "        **Siga estes passos:**\n",
        "\n",
        "        1.  **Avaliação de Fontes:** Para cada notícia e vídeo, utilize a pontuação de confiabilidade da fonte fornecida. Fontes com baixa pontuação (abaixo de 0.4) devem ser tratadas com grande ceticismo ou descartadas, a menos que corroboradas por fontes de alta confiança. Mencione as fontes de maior e menor confiabilidade encontradas, referenciando as pontuações fornecidas.\n",
        "        2.  **Análise de Conteúdo:** Leia o conteúdo disponível para cada notícia e ouça (metaforicamente) o conteúdo dos vídeos. Procure por:\n",
        "            *   Pontos principais e afirmações sendo feitas.\n",
        "            *   Evidências, dados, citações ou referências que suportem ou contradigam as afirmações.\n",
        "            *   Contradições internas no conteúdo.\n",
        "            *   Linguagem excessivamente emocional, sensacionalista ou parcial.\n",
        "            *   Indicações de sátira ou opinião disfarçada de notícia (embora o Agente 2 já tenha pré-analisado isso, reavalie se encontrar sinais fortes).\n",
        "        3.  **Comparação Cruzada:** Compare as informações apresentadas em diferentes notícias e vídeos. As fontes confiáveis concordam entre si? Há grandes discrepâncias?\n",
        "        4.  **Determinação da Veracidade:** Com base na sua análise das fontes, conteúdo e comparações, determine se a informação central do tópico parece ser:\n",
        "            *   **Verdadeira:** Há forte evidência de múltiplas fontes confiáveis corroborando a informação.\n",
        "            *   **Falsa:** Há forte evidência de que a informação é incorreta, ou é contradita por múltiplas fontes confiáveis, ou vem apenas de fontes não confiáveis.\n",
        "            *   **Enganosa/Parcial:** A informação contém elementos de verdade, mas é apresentada de forma distorcida, exagerada, incompleta ou com forte viés. Pode misturar fatos com opinião ou omitir contexto crucial.\n",
        "            *   **Não Verificável:** Não há informação suficiente ou as fontes são muito pouco confiáveis para fazer uma determinação clara.\n",
        "\n",
        "        **Formato de Saída:**\n",
        "\n",
        "        Apresente sua análise de forma clara e organizada, seguindo este formato:\n",
        "\n",
        "        ---\n",
        "        **Análise de Veracidade sobre [Tópico Principal]**\n",
        "        *Data da Análise: [Data de Hoje]*\n",
        "\n",
        "        **Resumo Inicial:** [Breve resumo da sua descoberta principal - Verdadeira, Falsa, Enganosa, Não Verificável - e a principal razão.]\n",
        "\n",
        "        **Fontes Avaliadas:**\n",
        "        *   Fontes de Alta Confiabilidade Notadas: [Lista de URLs com alta pontuação e seus títulos, se aplicável, usando as pontuações fornecidas.]\n",
        "        *   Fontes de Baixa Confiabilidade Notadas: [Lista de URLs com baixa pontuação e seus títulos, se aplicável, usando as pontuações fornecidas.]\n",
        "\n",
        "        **Pontos Chave da Análise de Conteúdo e Comparação:**\n",
        "        *   [Use marcadores para listar os principais pontos, evidências encontradas, contradições ou corroborações entre fontes.]\n",
        "        *   [Mencione exemplos específicos de linguagem tendenciosa ou exagero, se relevantes.]\n",
        "\n",
        "        **Determinação Final:**\n",
        "        [Declare claramente sua determinação: Verdadeira, Falsa, Enganosa/Parcial, ou Não Verificável. Justifique concisamente esta determinação com base nos pontos acima.]\n",
        "        ---\n",
        "\n",
        "        Seja objetivo, imparcial e baseie sua análise estritamente nas informações fornecidas e na avaliação das fontes fornecidas. Se não houver informações suficientes ou confiáveis, declare a informação como \"Não Verificável\".\n",
        "        \"\"\",\n",
        "        description=\"Agente que analisa notícias e verifica a credibilidade das fontes fornecidas, fornecendo uma determinação de veracidade.\",\n",
        "    )\n",
        "\n",
        "    noticias = resultados.get(\"noticias\", [])\n",
        "    videos = resultados.get(\"videos\", [])\n",
        "\n",
        "    informacoes_para_agente = \"\"\n",
        "    # Não precisamos recalcular confiabilidades aqui, vamos usar as existentes\n",
        "    confiabilidades_usadas = {}\n",
        "\n",
        "    # Adicionar notícias com confiabilidade ao input do agente\n",
        "    informacoes_para_agente += \"**Notícias:**\\n\"\n",
        "    if noticias:\n",
        "        for noticia in noticias:\n",
        "            link = noticia.get('link')\n",
        "            titulo = noticia.get('titulo', 'Sem Título')\n",
        "            if link:\n",
        "                # Usamos a confiabilidade pré-calculada, ou N/A se não encontrada\n",
        "                confiabilidade = confiabilidades_existentes.get(link, 'N/A')\n",
        "                # Armazenamos as confiabilidades usadas para o retorno, se necessário\n",
        "                if confiabilidade != 'N/A':\n",
        "                     confiabilidades_usadas[link] = confiabilidade\n",
        "                informacoes_para_agente += f\"- [Título: {titulo}] [Link: {link}] [Confiabilidade: {confiabilidade:.2f}]\\n\" if isinstance(confiabilidade, float) else f\"- [Título: {titulo}] [Link: {link}] [Confiabilidade: {confiabilidade}]\\n\"\n",
        "            else:\n",
        "                 informacoes_para_agente += f\"- [Título: {titulo}] [Link: N/A] [Confiabilidade: N/A]\\n\"\n",
        "    else:\n",
        "        informacoes_para_agente += \"Nenhuma notícia encontrada.\\n\"\n",
        "\n",
        "    # Adicionar vídeos com confiabilidade ao input do agente\n",
        "    informacoes_para_agente += \"\\n**Vídeos:**\\n\"\n",
        "    if videos:\n",
        "        for video in videos:\n",
        "            link = video.get('link')\n",
        "            titulo = video.get('titulo', 'Sem Título')\n",
        "            if link:\n",
        "                 # Usamos a confiabilidade pré-calculada, ou N/A se não encontrada\n",
        "                confiabilidade = confiabilidades_existentes.get(link, 'N/A')\n",
        "                # Armazenamos as confiabilidades usadas para o retorno, se necessário\n",
        "                if confiabilidade != 'N/A':\n",
        "                    confiabilidades_usadas[link] = confiabilidade\n",
        "                informacoes_para_agente += f\"- [Título: {titulo}] [Link: {link}] [Confiabilidade: {confiabilidade:.2f}]\\n\" if isinstance(confiabilidade, float) else f\"- [Título: {titulo}] [Link: {link}] [Confiabilidade: {confiabilidade}]\\n\"\n",
        "            else:\n",
        "                informacoes_para_agente += f\"- [Título: {titulo}] [Link: N/A] [Confiabilidade: N/A]\\n\"\n",
        "    else:\n",
        "        informacoes_para_agente += \"Nenhum vídeo encontrado.\\n\"\n",
        "\n",
        "\n",
        "    # Preparar a entrada final para o agente analisador\n",
        "    # Incluímos as confiabilidades conhecidas explicitamente na instrução do agente\n",
        "    entrada_do_agente_analisador = f\"\"\"\n",
        "    Análise de Veracidade de Notícias e Vídeos\n",
        "\n",
        "    **Tópico:** {topico}\n",
        "    **Data de Hoje:** {data_de_hoje}\n",
        "\n",
        "    **Informações Coletadas:**\n",
        "    {informacoes_para_agente}\n",
        "\n",
        "    **Confiabilidades Fornecidas:**\n",
        "    {confiabilidades_existentes}\n",
        "\n",
        "    Por favor, analise as informações acima seguindo os passos definidos e gere a análise no formato de saída especificado, utilizando as confiabilidades fornecidas.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n Enviando para Agente 4 para Análise...\")\n",
        "    analise = call_agent(analisador, entrada_do_agente_analisador)\n",
        "\n",
        "    # Retorna a análise do agente e as pontuações de confiabilidade que foram usadas\n",
        "    return {\"analise\": analise, \"confiabilidades\": confiabilidades_usadas}"
      ],
      "metadata": {
        "id": "y3VO1uo5_ghO"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# --- Agente 5: Classificação --- #\n",
        "######################################\n",
        "def agente_classificador(analise, data_de_hoje):\n",
        "    classificador = Agent(\n",
        "        name=\"agente_classificador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é um especialista em análise de informações e identificação de conteúdo tendencioso ou gerado por IA.\n",
        "        Sua tarefa é analisar o resultado da análise do Agente 4 e classificá-la como \"possível verdade\", \"possível mentira\" ou \"possível dado exagerado\".\n",
        "\n",
        "        Passos:\n",
        "        1. Identifique e liste os principais pontos da análise do Agente 4.\n",
        "        2. Analise o resultado da análise do Agente 4, procurando por:\n",
        "           * Linguagem tendenciosa ou sensacionalista.\n",
        "           * Afirmações exageradas ou sem evidências.\n",
        "           * Possível conteúdo gerado por IA que possa comprometer a informação.\n",
        "        3. Com base em sua análise, classifique a informação como:\n",
        "           * \"Possível verdade\": Se a análise do Agente 4 indicar que a informação é provavelmente verdadeira e não houver sinais de conteúdo tendencioso ou gerado por IA.\n",
        "           * \"Possível mentira\": Se a análise do Agente 4 indicar que a informação é provavelmente falsa ou houver fortes sinais de conteúdo tendencioso ou gerado por IA.\n",
        "           * \"Possível dado exagerado\": Se a análise do Agente 4 indicar que a informação pode conter exageros ou distorções, mesmo que não seja totalmente falsa.\n",
        "        4. Gere um resumo detalhado da sua análise, explicando os motivos da sua classificação.\n",
        "\n",
        "        Seja objetivo e imparcial em sua análise.\n",
        "        \"\"\",\n",
        "        description=\"Agente que refina a análise do Agente 4 e classifica a informação.\",\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_classificador = f\"Análise do Agente 4: {analise}\\nData de hoje: {data_de_hoje}\\nPor favor, analise a análise do Agente 4 e classifique a informação como 'possível verdade', 'possível mentira' ou 'possível dado exagerado', gerando um resumo detalhado da sua análise.\"\n",
        "    classificacao = call_agent(classificador, entrada_do_agente_classificador)\n",
        "    return classificacao"
      ],
      "metadata": {
        "id": "uOqlg2TRLVh1"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 6: Verificador Final --- #\n",
        "##########################################\n",
        "def agente_verificador_final(classificacao, data_de_hoje):\n",
        "  verificador = Agent(\n",
        "      name=\"agente_verificador_final\",\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      instruction=\"\"\"\n",
        "    Você é um especialista em verificação de fatos e análise de informações. Sua tarefa é analisar o resumo detalhado gerado pelo Agente 5, identificar palavras-chave, realizar buscas adicionais com essas palavras-chave e, com base em todas as informações disponíveis, determinar se a informação é verdadeira, falsa ou um exagero.\n",
        "\n",
        "    Passos:\n",
        "    1. Analise o resumo detalhado gerado pelo Agente 5 e identifique as palavras-chave mais relevantes.\n",
        "    2. Realize buscas adicionais no Google usando as palavras-chave identificadas para encontrar mais informações sobre o assunto.\n",
        "    3. Analise os resultados das buscas adicionais, procurando por:\n",
        "       * Fontes confiáveis que confirmem ou neguem a informação.\n",
        "       * Checagens de fatos (fact-checking) realizadas por agências de checagem de fatos.\n",
        "       * Declarações de especialistas ou autoridades que confirmem ou neguem a informação.\n",
        "    4. Com base em todas as informações disponíveis (o resumo do Agente 5 e os resultados das buscas adicionais), determine se a informação é:\n",
        "       * Verdadeira: Se houver evidências sólidas que confirmem a informação.\n",
        "       * Falsa: Se houver evidências sólidas que neguem a informação.\n",
        "       * Um exagero: Se a informação for parcialmente verdadeira, mas houver exageros ou distorções.\n",
        "    5. Gere um relatório final detalhado explicando sua decisão, incluindo as evidências que você usou para chegar a essa conclusão.\n",
        "\n",
        "    Seja objetivo e imparcial em sua análise.\n",
        "    \"\"\",\n",
        "      description=\"Agente que verifica a veracidade da informação com base no resumo do Agente 5 e em buscas adicionais.\",\n",
        "  )\n",
        "  # --- New Step: Identify keywords and perform additional searches ---\n",
        "  # This part would require some logic to extract keywords from the 'classificacao' string.\n",
        "  # A simple approach could be to ask Gemini itself to extract keywords first.\n",
        "  # Or, you could implement some basic keyword extraction techniques here.\n",
        "  keywords = \"extracted keywords from classification\" # Placeholder\n",
        "\n",
        "  additional_search_results = \"\"\n",
        "  if keywords:\n",
        "      print(f\"\\nPerforming additional searches for keywords: {keywords}...\")\n",
        "      try:\n",
        "          # Use Gemini with the Google Search tool for additional searches\n",
        "          search_response = client.models.generate_content(\n",
        "              model=MODEL_ID,\n",
        "              contents=f\"Search for information about: {keywords}\",\n",
        "              config={\"tools\": [{\"google_search\": {}}]}\n",
        "          )\n",
        "          if search_response and search_response.text:\n",
        "              additional_search_results = search_response.text\n",
        "              print(\"Additional search results obtained.\")\n",
        "          else:\n",
        "               print(\"Additional search did not return text.\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error during additional search: {e}\")\n",
        "          additional_search_results = \"Error performing additional search.\"\n",
        "\n",
        "  # Changed 'resumo_agente_3' to 'classificacao' to use the input variable\n",
        "  # --- Modify input to the agent to include search results ---\n",
        "  entrada_do_agente_verificador = f\"\"\"\n",
        "  Resumo do Agente 5: {classificacao}\n",
        "  Data de hoje: {data_de_hoje}\n",
        "\n",
        "  **Resultados de Buscas Adicionais:**\n",
        "  {additional_search_results}\n",
        "\n",
        "  Por favor, analise o resumo, utilize os resultados das buscas adicionais, e determine se a informação é verdadeira, falsa ou um exagero, gerando um relatório final detalhado.\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"\\nSending to Agente 6 for final verification...\")\n",
        "  relatorio_final = call_agent(verificador, entrada_do_agente_verificador)\n",
        "\n",
        "  return relatorio_final"
      ],
      "metadata": {
        "id": "_aTb1SdkLeT6"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 7: Avaliador de Perguntas --- #\n",
        "##########################################\n",
        "def agente_avaliador_de_perguntas(relatorio_agente_2, pergunta_agente_1, data_de_hoje):\n",
        "    avaliador = Agent(\n",
        "        name=\"agente_avaliador_de_perguntas\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "Você é um especialista em avaliação de perguntas e análise de informações.\n",
        "Sua tarefa é analisar o relatório do Agente 4 e a pergunta feita ao Agente 1, e determinar se a pergunta é relevante para verificar a veracidade da notícia, com base nas informações contidas no relatório.\n",
        "\n",
        "Passos:\n",
        "1. Analise o relatório do Agente 4 para identificar os principais pontos e informações relevantes sobre a notícia.\n",
        "2. Analise a pergunta feita ao Agente 1 para entender o que ela busca investigar.\n",
        "3. Determine se a pergunta é relevante para os seguintes aspectos:\n",
        "    * Verificar a veracidade das informações apresentadas no relatório.\n",
        "    * Investigar a credibilidade das fontes citadas no relatório.\n",
        "    * Explorar possíveis inconsistências ou contradições no relatório.\n",
        "    * Obter mais informações sobre os pontos-chave do relatório.\n",
        "4. Com base em sua análise, classifique a pergunta como \"Relevante\" ou \"Não Relevante\".\n",
        "5. Gere um relatório explicando sua decisão, justificando por que a pergunta é relevante ou não, com base nas informações do relatório. Seja objetivo e imparcial em sua análise.\n",
        "\"\"\",\n",
        "        description=\"Agente que avalia a relevância da pergunta feita ao Agente 1 com base no relatório do Agente 4.\",\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_avaliador = f\"Relatório do Agente 4: {relatorio_agente_2}\\nPergunta feita ao Agente 1: {pergunta_agente_1}\\nData de hoje: {data_de_hoje}\\nPor favor, analise o relatório e a pergunta, e determine se a pergunta é relevante para verificar a veracidade da notícia.\"\n",
        "    avaliacao = call_agent(avaliador, entrada_do_agente_avaliador)\n",
        "    return avaliacao"
      ],
      "metadata": {
        "id": "VVm6FVPk1FJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 8: Detalhamento --- # = Para aqueles que tem pressa em saber se a notífica é fato ou feke.\n",
        "##########################################\n",
        "def agente_detalhamento_final(relatorio_final, pergunta, data_de_hoje): detalhador = Agent( name=\"agente_detalhamento_final\", model=\"gemini-2.0-flash\", instruction=\"\"\" Você é um especialista em análise detalhada de notícias e identificação de informações falsas ou indeterminadas. Sua tarefa é analisar o relatório do Agente 7, a pergunta inicial feita ao Agente 1 e, com base nas informações do relatório, determinar se a pergunta é Verdadeira, Falsa ou Exagerada. Em seguida, você deve adicionar um cabeçalho ao relatório indicando a sua classificação e detalhar as informações falsas ou indeterminadas, fornecendo fontes relevantes. Além disso, você deve resumir o relatório do Agente 7 de forma clara e concisa, explicar as informações de forma acessível e deixar o texto \"mastigado\" para que qualquer pessoa possa entender a notícia e a pergunta. Passos: 1. Analise o relatório do Agente 7 para identificar a classificação geral da notícia (Verdadeiro, Falso ou Indeterminado). 2. Com base na classificação da notícia, classifique a pergunta inicial como: * Verdadeira: Se a notícia for classificada como Verdadeira. * Falsa: Se a notícia for classificada como Falsa. * Exagerada: Se a notícia for classificada como Indeterminado ou se o relatório indicar que a notícia contém exageros ou distorções. 3. Crie um cabeçalho para o relatório final com a seguinte formatação: 4. Resuma os principais pontos do relatório do Agente 7 em 3-5 frases. 5. Explique as informações de forma clara e acessível, usando uma linguagem simples e evitando jargões técnicos. 6. Forneça contexto adicional para ajudar os leitores a entender a notícia e a pergunta. 7. Use exemplos e analogias para ilustrar os conceitos mais complexos. \"\"\", description=\"Agente que detalha informações falsas ou indeterminadas, adiciona um cabeçalho ao relatório final e torna as informações mais acessíveis.\", ) # You'll need to add the logic here to use the 'detalhador' agent # Based on the rest of your code, you would likely call the agent like this: entrada_do_agente_detalhamento = f\"Relatório do Agente 7: {relatorio_final}\\nPergunta inicial: {pergunta}\\nData de hoje: {data_de_hoje}\\nPor favor, analise as informações e forneça um detalhamento final com um cabeçalho.\" detalhes = call_agent(detalhador, entrada_do_agente_detalhamento) return detalhes"
      ],
      "metadata": {
        "id": "BQ-l6PWs2LWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "print(\"🚀 Iniciando o Sistema de análise de Fake News de 8 Agentes 🚀\")\n",
        "\n",
        "# --- Obter o Tópico do Usuário ---\n",
        "topico = input(\"❓ Por favor, digite o TÓPICO, noticia ou pergunta ue você queira saber se é fake news: \")\n",
        "\n",
        "# Function to get content from a URL (you need to implement this)\n",
        "def get_article_content(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        # Find and extract the main content of the article. This is a simplified example.\n",
        "        # You might need to inspect the HTML structure of the websites you are scraping\n",
        "        # to find the correct tags or classes for the article content.\n",
        "        paragraphs = soup.find_all('p')\n",
        "        content = ' '.join([para.get_text() for para in paragraphs])\n",
        "        return content\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching content from {url}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing content from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Inserir lógica do sistema de agentes ################################################\n",
        "if not topico:\n",
        "    print(\"Você esqueceu de digitar o tópico!\")\n",
        "else:\n",
        "    print(f\"Maravilha! Vamos começar nossas análise em: {topico}\")\n",
        "\n",
        "    # --- Agente 1: Buscador de notícias ---\n",
        "    agente_1 = agente_buscador(topico, data_de_hoje)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 1 (Buscador) ---\\n\")\n",
        "\n",
        "    agente_1_string = \"\"\n",
        "    for key, value in agente_1.items():\n",
        "        agente_1_string += f\"**{key.replace('_', ' ').title()}**:\\n\"\n",
        "        if isinstance(value, list):\n",
        "            if value:\n",
        "                for item in value:\n",
        "                    if isinstance(item, dict) and 'titulo' in item and 'link' in item:\n",
        "                            agente_1_string += f\"- [{item['titulo']}]({item['link']})\\n\"\n",
        "                    else:\n",
        "                        agente_1_string += f\"- {item}\\n\"\n",
        "            else:\n",
        "                agente_1_string += \"Nenhum resultado encontrado.\\n\"\n",
        "        else:\n",
        "            agente_1_string += f\"{value}\\n\"\n",
        "        agente_1_string += \"\\n\"\n",
        "    display(to_markdown(agente_1_string))\n",
        "\n",
        "    # --- Agente 2: Detector de sátiras ---\n",
        "    agente_2_results = []\n",
        "    for noticia in agente_1.get(\"noticias\", []):\n",
        "        titulo = noticia.get(\"titulo\")\n",
        "        link = noticia.get(\"link\")\n",
        "        if titulo and link:\n",
        "            conteudo = get_article_content(link)\n",
        "            if conteudo:\n",
        "                is_satire = agente_deteccao_satira(titulo, conteudo, link)\n",
        "                agente_2_results.append({\"titulo\": titulo, \"link\": link, \"is_satire\": is_satire, \"url\": link}) # Store url for agente_3\n",
        "            else:\n",
        "                agente_2_results.append({\"titulo\": titulo, \"link\": link, \"is_satire\": \"Conteúdo não disponível\", \"url\": link}) # Store url for agente_3\n",
        "\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 2 (Agente detector de sátira) ---\\n\")\n",
        "    agente_2_string = \"\"\n",
        "    if agente_2_results:\n",
        "        for result in agente_2_results:\n",
        "            agente_2_string += f\"- **Título:** {result['titulo']}\\n\"\n",
        "            agente_2_string += f\"  **Link:** {result['link']}\\n\"\n",
        "            agente_2_string += f\"  **É Sátira:** {result['is_satire']}\\n\"\n",
        "            agente_2_string += \"\\n\"\n",
        "    else:\n",
        "        agente_2_string = \"Nenhum resultado de notícia para analisar.\"\n",
        "    display(to_markdown(agente_2_string))\n",
        "\n",
        "\n",
        "    # --- Agente 3: Avaliação de Fontes ---\n",
        "    agente_3_results = []\n",
        "    all_items_to_evaluate = agente_1.get(\"noticias\", []) + agente_1.get(\"videos_favor\", []) + agente_1.get(\"videos_contra\", [])\n",
        "\n",
        "    # Dicionário para armazenar as confiabilidades por link\n",
        "    confiabilidades_calculadas = {}\n",
        "\n",
        "    if all_items_to_evaluate:\n",
        "        for item in all_items_to_evaluate:\n",
        "            link = item.get(\"link\")\n",
        "            if link:\n",
        "                confiabilidade = agente_avaliacao_fontes(link) # Chamada original ao Agente 3\n",
        "                confiabilidades_calculadas[link] = confiabilidade # Armazena no dicionário\n",
        "                agente_3_results.append({\"titulo\": item.get(\"titulo\", \"N/A\"), \"link\": link, \"confiabilidade\": confiabilidade})\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 3 (Avaliador de Fontes) ---\\n\")\n",
        "    agente_3_string = \"\"\n",
        "    if agente_3_results:\n",
        "        for result in agente_3_results:\n",
        "            agente_3_string += f\"- **Título:** {result['titulo']}\\n\"\n",
        "            agente_3_string += f\"  **Link:** {result['link']}\\n\"\n",
        "            agente_3_string += f\"  **Confiabilidade:** {result['confiabilidade']:.2f}\\n\"\n",
        "            agente_3_string += \"\\n\"\n",
        "    else:\n",
        "        agente_3_string = \"Nenhum link para avaliar a confiabilidade.\"\n",
        "    display(to_markdown(agente_3_string))\n",
        "\n",
        "    # --- Agente 4: Analista (Melhorado - Corrigido) ---\n",
        "    print(\"\\n--- 🤖 Executando Agente 4 (Analisador) ---\")\n",
        "    # Passamos o dicionário de confiabilidades pré-calculadas para o Agente 4\n",
        "    agente_4_result = agente_analisador(agente_1, data_de_hoje, confiabilidades_calculadas)\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 4 (Analisador) ---\\n\")\n",
        "    analise_text = agente_4_result.get(\"analise\", \"Nenhuma análise gerada pelo Agente 4.\")\n",
        "    display(to_markdown(analise_text))\n",
        "\n",
        "        # --- Agente 5: Classificação ---\n",
        "    # A função agente_classificador real precisa estar definida aqui ou importada\n",
        "    # Chamamos o Agente 5, passando a análise do Agente 4 e a data\n",
        "    print(\"\\n--- 🤖 Executando Agente 5 (Classificação) ---\")\n",
        "\n",
        "# --- Agente 5: Classificação ---\n",
        "    # A função agente_classificador real precisa estar definida aqui ou importada\n",
        "    # Chamamos o Agente 5, passando a análise do Agente 4 e a data\n",
        "    print(\"\\n--- 🤖 Executando Agente 5 (Classificação) ---\")\n",
        "\n",
        "    # Chamamos o Agente 5, passando a análise do Agente 4 (o texto extraído) e a data\n",
        "    agente_5_result = agente_classificador(analise_text, data_de_hoje) # Passa apenas o texto da análise do Agente 4\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 5 (Classificação) ---\\n\")\n",
        "    agente_5_string = \"\"\n",
        "    # Agente 5 retorna diretamente a string de classificação e análise\n",
        "    agente_5_string += agente_5_result\n",
        "\n",
        "    display(to_markdown(agente_5_string))\n",
        "\n",
        "     # --- Agente 6: Verificador Final ---\n",
        "    # A função agente_verificador_final real precisa estar definida aqui ou importada\n",
        "    # Chamamos o Agente 6, passando a classificação/resumo do Agente 5 e a data\n",
        "    print(\"\\n--- 🤖 Executando Agente 6 (Verificador Final) ---\")\n",
        "\n",
        "    # O Agente 5 retorna o resultado da chamada ao call_agent, que contém a classificação E o resumo detalhado.\n",
        "    # A instrução do Agente 6 indica que ele precisa do \"resumo detalhado gerado pelo Agente 5\".\n",
        "    # Portanto, passamos a string completa retornada pelo Agente 5.\n",
        "    agente_6_result = agente_verificador_final(agente_5_result, data_de_hoje) # Passa o resultado COMPLETO do Agente 5\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 6 (Verificador Final) ---\\n\")\n",
        "    agente_6_string = \"\"\n",
        "    # Agente 6 retorna diretamente o relatório final como string\n",
        "    agente_6_string += agente_6_result\n",
        "\n",
        "    display(to_markdown(agente_6_string))\n",
        "\n",
        "# --- Agente 7: Avaliador de Perguntas ---\n",
        "    # A função agente_avaliador_de_perguntas real precisa estar definida aqui ou importada\n",
        "    # Chamamos o Agente 7, passando os inputs necessários\n",
        "    print(\"\\n--- 🤖 Executando Agente 7 (Avaliador de Perguntas) ---\")\n",
        "    # O Agente 7 espera:\n",
        "    # 1. relatorio_agente_2: Passamos o texto da análise do Agente 4 (analise_text),\n",
        "    #    pois a instrução interna do Agente 7 se refere ao \"relatório do Agente 4\".\n",
        "    # 2. pergunta_agente_1: Passamos o tópico original (topico).\n",
        "    # 3. data_de_hoje: Já disponível.\n",
        "    # Use the defined variable 'analise_text' instead of 'agente_4_analise_text'\n",
        "    agente_7_result = agente_avaliador_de_perguntas(analise_text, topico, data_de_hoje)\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Agente 7 (Avaliador de Perguntas) ---\\n\")\n",
        "    agente_7_string = \"\"\n",
        "    # Agente 7 retorna diretamente o relatório de avaliação da pergunta como string\n",
        "    agente_7_string += agente_7_result\n",
        "\n",
        "    display(to_markdown(agente_7_string))\n",
        "\n",
        "        # --- Agente 8: Detalhamento ---\n",
        "    # A função agente_detalhamento_final real precisa estar definida aqui ou importada\n",
        "    # Chamamos o Agente 8, passando os inputs necessários\n",
        "    print(\"\\n--- 🤖 Executando Agente 8 (Detalhamento Final) ---\")\n",
        "    # O Agente 8 espera:\n",
        "    # 1. relatorio_final: A instrução interna menciona o \"relatório do Agente 7\", mas o parâmetro se chama 'relatorio_final'\n",
        "    #    que geralmente viria do Agente 6. Vamos passar o resultado do Agente 6 ('agente_6_result'),\n",
        "    #    pois é o que o nome do parâmetro sugere, e o modelo de IA terá que lidar com a inconsistência na instrução.\n",
        "    # 2. pergunta: O tópico original (topico).\n",
        "    # 3. data_de_hoje: Já disponível.\n",
        "\n",
        "    # Chamamos o Agente 8\n",
        "    agente_8_result = agente_detalhamento_final(agente_6_result, topico, data_de_hoje) # Passa o resultado COMPLETO do Agente 6 e o tópico\n",
        "\n",
        "    print(\"\\n--- 📝 Resultado do Sistema (Relatório Final Detalhado) ---\\n\")\n",
        "    agente_8_string = \"\"\n",
        "    # Agente 8 retorna diretamente o relatório detalhado como string\n",
        "    agente_8_string += agente_8_result\n",
        "\n",
        "    display(to_markdown(agente_8_string))\n",
        "\n",
        "    print(\"\\n🎉 Sistema de Análise de Fake News Concluído! 🎉\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xzI6LKzxxnN",
        "outputId": "a9cfb382-d7a7-48d1-e404-4a78e29f4b12"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Iniciando o Sistema de análise de Fake News de 8 Agentes 🚀\n",
            "❓ Por favor, digite o TÓPICO, noticia ou pergunta ue você queira saber se é fake news: test\n",
            "Maravilha! Vamos começar nossas análise em: test\n",
            "\n",
            "--- 📝 Resultado do Agente 1 (Buscador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Noticias**:\n> - [Speedtest by Ookla - The Global Broadband Speed Test](https://www.speedtest.net/)\n> - [TEST Definition & Meaning - Merriam-Webster](https://www.merriam-webster.com/dictionary/test)\n> - [Take a Test](https://implicit.harvard.edu/implicit/takeatest.html)\n> - [FairTest Home - Fairtest](https://fairtest.org/)\n> - [Join a Test Meeting | Zoom](https://zoom.us/test)\n> - [America's Test Kitchen: Trusted Recipes and Insights for Home ...](https://www.americastestkitchen.com/)\n> - [CTBTO: Homepage](https://www.ctbto.org/)\n> - [Civics (History and Government) Questions for the Naturalization Test](https://www.uscis.gov/sites/default/files/document/questions-and-answers/100q.pdf)\n> - [Test your English online](https://englishtest.duolingo.com/applicants)\n> - [The Comprehensive Nuclear-Test-Ban Treaty (CTBT) | CTBTO](https://www.ctbto.org/our-mission/the-treaty)\n> \n> **Videos Favor**:\n> - [Educational Videos | Women's Health](https://womenshealth.labcorp.com/educational-videos)\n> - [Check out the official music video for \"NEED A FAVOR\" >>>https ...](https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-official-music-video-for-need-a-favor-httpsyoutubep1nrboaltzu/722070149284838/)\n> - [This is how the YouTube algorithm works: (a guide for beginners) : r ...](https://www.reddit.com/r/NewTubers/comments/1569u08/this_is_how_the_youtube_algorithm_works_a_guide/)\n> - [Check out the music video for \"NEED A FAVOR\" and let me know ...](https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-music-video-for-need-a-favor-and-let-me-know-what-you-think/722067599285093/)\n> - [Respiratory Protection - Training Videos | Occupational Safety and ...](http://www.osha.gov/respiratory-protection/training)\n> - [Everything You Need to Know About Social Media Algorithms ...](https://sproutsocial.com/insights/social-media-algorithms/)\n> - [TikTok Algorithm Guide 2025: How to Get Your Videos on FYPs](https://buffer.com/resources/tiktok-algorithm/)\n> - [ODAC Unanimously Votes in Favor of MRD Testing as Early ...](https://www.myeloma.org/blog/dr-duries/odac-unanimously-in-favor-mrd-testing-early-endpoint-myeloma)\n> - [Synchronized eye movements predict test scores in online video ...](https://www.pnas.org/doi/10.1073/pnas.2016980118)\n> - [Facebook to test showing ads mid-video with publisher revenue split ...](https://techcrunch.com/2017/01/09/facebook-to-test-showing-ads-mid-video-with-publisher-revenue-split/)\n> \n> **Videos Contra**:\n> - [Can You Fool A Self Driving Car? - YouTube](https://www.youtube.com/watch?v=IQJL3htsDyQ)\n> - [Impact Texas Drivers](https://impacttexasdrivers.dps.texas.gov/)\n> - [Impact Texas Drivers (ITD) Program | Department of Public Safety](https://www.dps.texas.gov/section/driver-license/impact-texas-drivers-itd-program)\n> - [Home - Automotive Services - Library Guides at Contra Costa ...](https://libguides.contracosta.edu/auser)\n> - [The best D-Pad for Contra and fighting game (Anbernics, PowKiddy ...](https://www.reddit.com/r/SBCGaming/comments/136xvm1/the_best_dpad_for_contra_and_fighting_game/)\n> - [Videos - Central Contra Costa Sanitary District](https://www.centralsan.org/videos)\n> - [Fire Alarm Systems Training Videos | Potter Electric](https://www.pottersignal.com/training/videos)\n> - [Video Visits With Your Doctor | Contra Costa Health](https://www.cchealth.org/get-care/medical-center-services/video-visits-with-your-doctor)\n> - [Respiratory Protection - Training Videos | Occupational Safety and ...](http://www.osha.gov/respiratory-protection/training)\n> - [Testing the Efficacy of ... - JMIR Public Health and Surveillance](https://publichealth.jmir.org/2022/6/e34615/)\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching content from https://www.speedtest.net/: 403 Client Error: Forbidden for url: https://www.speedtest.net/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching content from https://englishtest.duolingo.com/applicants: 406 Client Error: Not Acceptable for url: https://englishtest.duolingo.com/applicants\n",
            "\n",
            "--- 📝 Resultado do Agente 2 (Agente detector de sátira) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> - **Título:** Speedtest by Ookla - The Global Broadband Speed Test\n>   **Link:** https://www.speedtest.net/\n>   **É Sátira:** Conteúdo não disponível\n> \n> - **Título:** TEST Definition & Meaning - Merriam-Webster\n>   **Link:** https://www.merriam-webster.com/dictionary/test\n>   **É Sátira:** None\n> \n> - **Título:** Take a Test\n>   **Link:** https://implicit.harvard.edu/implicit/takeatest.html\n>   **É Sátira:** None\n> \n> - **Título:** FairTest Home - Fairtest\n>   **Link:** https://fairtest.org/\n>   **É Sátira:** None\n> \n> - **Título:** Join a Test Meeting | Zoom\n>   **Link:** https://zoom.us/test\n>   **É Sátira:** None\n> \n> - **Título:** America's Test Kitchen: Trusted Recipes and Insights for Home ...\n>   **Link:** https://www.americastestkitchen.com/\n>   **É Sátira:** None\n> \n> - **Título:** CTBTO: Homepage\n>   **Link:** https://www.ctbto.org/\n>   **É Sátira:** None\n> \n> - **Título:** Civics (History and Government) Questions for the Naturalization Test\n>   **Link:** https://www.uscis.gov/sites/default/files/document/questions-and-answers/100q.pdf\n>   **É Sátira:** Conteúdo não disponível\n> \n> - **Título:** Test your English online\n>   **Link:** https://englishtest.duolingo.com/applicants\n>   **É Sátira:** Conteúdo não disponível\n> \n> - **Título:** The Comprehensive Nuclear-Test-Ban Treaty (CTBT) | CTBTO\n>   **Link:** https://www.ctbto.org/our-mission/the-treaty\n>   **É Sátira:** None\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avaliação de Gemini Search para https://www.speedtest.net/: Para avaliar a confiabilidade do Speedtest.net como fonte de notícias, é importante considerar o foco principal do site e a natureza das informações que ele geralmente divulga. Normalmente, o Speedtes...\n",
            "Avaliação de Gemini Search para https://www.merriam-webster.com/dictionary/test: Para avaliar a confiabilidade da fonte de notícias do site merriam-webster.com, é importante analisar o tipo de conteúdo que ele oferece e sua reputação. Merriam-Webster é principalmente um dicionário...\n",
            "Avaliação de Gemini Search para https://implicit.harvard.edu/implicit/takeatest.html: O site https://implicit.harvard.edu/implicit/takeatest.html hospeda o \"Project Implicit\", que é um projeto de pesquisa da Universidade de Harvard, juntamente com as Universidades de Washington e Virgí...\n",
            "Avaliação de Gemini Search para https://fairtest.org/: Para avaliar a confiabilidade do site fairtest.org, realizarei pesquisas para determinar seu histórico de reportagens factuais.\n",
            "\n",
            "FairTest.org é o site do The National Center for Fair & Open Testing. S...\n",
            "Avaliação de Gemini Search para https://zoom.us/test: O site zoom.us/test não é uma fonte de notícias. É uma página de teste fornecida pela Zoom para que os usuários possam verificar o áudio e o vídeo antes de participar de uma reunião.\n",
            "\n",
            "O Zoom, de forma...\n",
            "Avaliação de Gemini Search para https://www.americastestkitchen.com/: Para avaliar a confiabilidade do site America's Test Kitchen como fonte de notícias, precisamos analisar sua abordagem editorial, reputação e verificar se há casos conhecidos de disseminação de inform...\n",
            "Avaliação de Gemini Search para https://www.ctbto.org/: Para avaliar a confiabilidade do site de notícias [https://www.ctbto.org/](https://www.ctbto.org/), precisamos analisar seu histórico, missão e conteúdo publicado. O CTBTO (Comprehensive Nuclear-Test-...\n",
            "Avaliação de Gemini Search para https://www.uscis.gov/sites/default/files/document/questions-and-answers/100q.pdf: O site do USCIS (.gov) é uma fonte oficial do governo dos Estados Unidos. Sites .gov são geralmente fontes confiáveis de informação, pois são gerenciados por agências governamentais e estão sujeitos a...\n",
            "Avaliação de Gemini Search para https://englishtest.duolingo.com/applicants: Para avaliar a confiabilidade do site englishtest.duolingo.com/applicants, é importante entender seu propósito. O site é a página oficial do Duolingo English Test, um exame de proficiência em inglês. ...\n",
            "Avaliação de Gemini Search para https://www.ctbto.org/our-mission/the-treaty: Para avaliar a confiabilidade da fonte de notícias do site [https://www.ctbto.org/our-mission/the-treaty](https://www.ctbto.org/our-mission/the-treaty), é importante considerar o seguinte:\n",
            "\n",
            "*   **Natu...\n",
            "Avaliação de Gemini Search para https://womenshealth.labcorp.com/educational-videos: Para avaliar a confiabilidade do site womenshealth.labcorp.com/educational-videos, vou pesquisar sobre a reputação da Labcorp como fonte de informação de saúde e verificar se há relatos de notícias fa...\n",
            "Avaliação de Gemini Search para https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-official-music-video-for-need-a-favor-httpsyoutubep1nrboaltzu/722070149284838/: Para avaliar a confiabilidade da página do Facebook \"Jelly Roll\", é importante considerar o seguinte:\n",
            "\n",
            "*   **Natureza do Conteúdo:** A página parece ser a página oficial de um artista musical, \"Jelly ...\n",
            "Avaliação de Gemini Search para https://www.reddit.com/r/NewTubers/comments/1569u08/this_is_how_the_youtube_algorithm_works_a_guide/: Para avaliar a confiabilidade de uma fonte de notícias como um tópico do Reddit (/r/newtubers/comments/1569u08/this_is_how_the_youtube_algorithm_works_a_guide/), é necessário considerar vários fatores...\n",
            "Avaliação de Gemini Search para https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-music-video-for-need-a-favor-and-let-me-know-what-you-think/722067599285093/: Para avaliar a confiabilidade da fonte de notícias do site fornecido, analisarei o seguinte:\n",
            "\n",
            "*   A fonte em si (neste caso, uma página do Facebook chamada \"Jelly Roll\")\n",
            "*   O conteúdo compartilhado (...\n",
            "Avaliação de Gemini Search para http://www.osha.gov/respiratory-protection/training: Para avaliar a confiabilidade de osha.gov/respiratory-protection/training, é importante determinar a natureza da fonte. O site pertence à Administração de Segurança e Saúde Ocupacional (OSHA), uma agê...\n",
            "Avaliação de Gemini Search para https://sproutsocial.com/insights/social-media-algorithms/: Para avaliar a confiabilidade do site Sproutsocial.com/insights/social-media-algorithms, preciso analisar seu histórico de publicação e reputação.\n",
            "\n",
            "Com base nas informações disponíveis, aqui está uma ...\n",
            "Avaliação de Gemini Search para https://buffer.com/resources/tiktok-algorithm/: Para avaliar a confiabilidade de buffer.com/resources/tiktok-algorithm/, preciso pesquisar sobre o site e seu histórico de precisão factual. Também procurarei por quaisquer verificações de fatos ou an...\n",
            "Avaliação de Gemini Search para https://www.myeloma.org/blog/dr-duries/odac-unanimously-in-favor-mrd-testing-early-endpoint-myeloma: Para avaliar a confiabilidade de myeloma.org, investigarei sua reputação, propósito e transparência. Também procurarei por verificações de fatos ou análises de terceiros da fonte. Além disso, procurar...\n",
            "Avaliação de Gemini Search para https://www.pnas.org/doi/10.1073/pnas.2016980118: Para avaliar a confiabilidade do site [https://www.pnas.org/doi/10.1073/pnas.2016980118](https://www.pnas.org/doi/10.1073/pnas.2016980118), é crucial considerar a fonte que ele representa.\n",
            "\n",
            "O site [ht...\n",
            "Avaliação de Gemini Search para https://techcrunch.com/2017/01/09/facebook-to-test-showing-ads-mid-video-with-publisher-revenue-split/: Para avaliar a confiabilidade do TechCrunch, analisarei sua reputação geral e o histórico de relatórios. O TechCrunch é uma fonte de notícias geralmente confiável, conhecida por cobrir startups de tec...\n",
            "Avaliação de Gemini Search para https://www.youtube.com/watch?v=IQJL3htsDyQ: Para avaliar a confiabilidade da fonte de notícias do YouTube que você forneceu, é necessário analisar vários fatores, incluindo a reputação do canal, a precisão factual do conteúdo que ele apresenta ...\n",
            "Avaliação de Gemini Search para https://impacttexasdrivers.dps.texas.gov/: Para avaliar a confiabilidade do site de notícias https://impacttexasdrivers.dps.texas.gov/, farei algumas pesquisas para entender o propósito do site e o tipo de conteúdo que ele publica. Depois de o...\n",
            "Avaliação de Gemini Search para https://www.dps.texas.gov/section/driver-license/impact-texas-drivers-itd-program: O site da Texas Department of Public Safety (DPS) visa fornecer informações precisas e oportunas. O DPS faz todos os esforços para garantir a exatidão dos relatórios por meio de treinamento e verifica...\n",
            "Avaliação de Gemini Search para https://libguides.contracosta.edu/auser: Para avaliar a confiabilidade do site [https://libguides.contracosta.edu/auser](https://libguides.contracosta.edu/auser), é importante considerar o seguinte:\n",
            "\n",
            "*   **Propósito do Site:** O site parece ...\n",
            "Avaliação de Gemini Search para https://www.reddit.com/r/SBCGaming/comments/136xvm1/the_best_dpad_for_contra_and_fighting_game/: Para avaliar a confiabilidade da fonte de notícias do site Reddit, especificamente o subreddit r/sbcgaming, é importante considerar o seguinte:\n",
            "\n",
            "*   **Natureza do Reddit:** O Reddit é uma plataforma d...\n",
            "Avaliação de Gemini Search para https://www.centralsan.org/videos: O site https://www.centralsan.org/ é o site oficial do Distrito Sanitário Central de Contra Costa, uma agência pública que presta serviços essenciais de transporte e tratamento de esgoto sanitário par...\n",
            "Avaliação de Gemini Search para https://www.pottersignal.com/training/videos: O site pottersignal.com pertence à Potter Electric Signal Company, uma empresa com reputação estabelecida como designer e fabricante de controles eletrónicos e dispositivos de monitoramento para os me...\n",
            "Avaliação de Gemini Search para https://www.cchealth.org/get-care/medical-center-services/video-visits-with-your-doctor: Para avaliar a confiabilidade do site www.cchealth.org, é importante entender o propósito e a afiliação da página. Em geral, sites de departamentos de saúde pública são fontes confiáveis de informação...\n",
            "Avaliação de Gemini Search para http://www.osha.gov/respiratory-protection/training: O site da OSHA (Occupational Safety and Health Administration, osha.gov) é uma fonte geralmente confiável de informações sobre segurança e saúde no trabalho. A OSHA é uma agência do governo dos EUA. O...\n",
            "Avaliação de Gemini Search para https://publichealth.jmir.org/2022/6/e34615/: Para avaliar a confiabilidade do site publichealth.jmir.org, preciso analisar sua reputação, políticas editoriais e precisão factual. Também procurarei exemplos de notícias recentes publicadas pelo si...\n",
            "\n",
            "--- 📝 Resultado do Agente 3 (Avaliador de Fontes) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> - **Título:** Speedtest by Ookla - The Global Broadband Speed Test\n>   **Link:** https://www.speedtest.net/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** TEST Definition & Meaning - Merriam-Webster\n>   **Link:** https://www.merriam-webster.com/dictionary/test\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Take a Test\n>   **Link:** https://implicit.harvard.edu/implicit/takeatest.html\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** FairTest Home - Fairtest\n>   **Link:** https://fairtest.org/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Join a Test Meeting | Zoom\n>   **Link:** https://zoom.us/test\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** America's Test Kitchen: Trusted Recipes and Insights for Home ...\n>   **Link:** https://www.americastestkitchen.com/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** CTBTO: Homepage\n>   **Link:** https://www.ctbto.org/\n>   **Confiabilidade:** 0.10\n> \n> - **Título:** Civics (History and Government) Questions for the Naturalization Test\n>   **Link:** https://www.uscis.gov/sites/default/files/document/questions-and-answers/100q.pdf\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Test your English online\n>   **Link:** https://englishtest.duolingo.com/applicants\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** The Comprehensive Nuclear-Test-Ban Treaty (CTBT) | CTBTO\n>   **Link:** https://www.ctbto.org/our-mission/the-treaty\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Educational Videos | Women's Health\n>   **Link:** https://womenshealth.labcorp.com/educational-videos\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Check out the official music video for \"NEED A FAVOR\" >>>https ...\n>   **Link:** https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-official-music-video-for-need-a-favor-httpsyoutubep1nrboaltzu/722070149284838/\n>   **Confiabilidade:** 0.10\n> \n> - **Título:** This is how the YouTube algorithm works: (a guide for beginners) : r ...\n>   **Link:** https://www.reddit.com/r/NewTubers/comments/1569u08/this_is_how_the_youtube_algorithm_works_a_guide/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Check out the music video for \"NEED A FAVOR\" and let me know ...\n>   **Link:** https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-music-video-for-need-a-favor-and-let-me-know-what-you-think/722067599285093/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Respiratory Protection - Training Videos | Occupational Safety and ...\n>   **Link:** http://www.osha.gov/respiratory-protection/training\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Everything You Need to Know About Social Media Algorithms ...\n>   **Link:** https://sproutsocial.com/insights/social-media-algorithms/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** TikTok Algorithm Guide 2025: How to Get Your Videos on FYPs\n>   **Link:** https://buffer.com/resources/tiktok-algorithm/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** ODAC Unanimously Votes in Favor of MRD Testing as Early ...\n>   **Link:** https://www.myeloma.org/blog/dr-duries/odac-unanimously-in-favor-mrd-testing-early-endpoint-myeloma\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Synchronized eye movements predict test scores in online video ...\n>   **Link:** https://www.pnas.org/doi/10.1073/pnas.2016980118\n>   **Confiabilidade:** 0.90\n> \n> - **Título:** Facebook to test showing ads mid-video with publisher revenue split ...\n>   **Link:** https://techcrunch.com/2017/01/09/facebook-to-test-showing-ads-mid-video-with-publisher-revenue-split/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Can You Fool A Self Driving Car? - YouTube\n>   **Link:** https://www.youtube.com/watch?v=IQJL3htsDyQ\n>   **Confiabilidade:** 0.10\n> \n> - **Título:** Impact Texas Drivers\n>   **Link:** https://impacttexasdrivers.dps.texas.gov/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Impact Texas Drivers (ITD) Program | Department of Public Safety\n>   **Link:** https://www.dps.texas.gov/section/driver-license/impact-texas-drivers-itd-program\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Home - Automotive Services - Library Guides at Contra Costa ...\n>   **Link:** https://libguides.contracosta.edu/auser\n>   **Confiabilidade:** 0.10\n> \n> - **Título:** The best D-Pad for Contra and fighting game (Anbernics, PowKiddy ...\n>   **Link:** https://www.reddit.com/r/SBCGaming/comments/136xvm1/the_best_dpad_for_contra_and_fighting_game/\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Videos - Central Contra Costa Sanitary District\n>   **Link:** https://www.centralsan.org/videos\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Fire Alarm Systems Training Videos | Potter Electric\n>   **Link:** https://www.pottersignal.com/training/videos\n>   **Confiabilidade:** 0.10\n> \n> - **Título:** Video Visits With Your Doctor | Contra Costa Health\n>   **Link:** https://www.cchealth.org/get-care/medical-center-services/video-visits-with-your-doctor\n>   **Confiabilidade:** 0.90\n> \n> - **Título:** Respiratory Protection - Training Videos | Occupational Safety and ...\n>   **Link:** http://www.osha.gov/respiratory-protection/training\n>   **Confiabilidade:** 0.50\n> \n> - **Título:** Testing the Efficacy of ... - JMIR Public Health and Surveillance\n>   **Link:** https://publichealth.jmir.org/2022/6/e34615/\n>   **Confiabilidade:** 0.10\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🤖 Executando Agente 4 (Analisador) ---\n",
            "\n",
            " Enviando para Agente 4 para Análise...\n",
            "\n",
            "--- 📝 Resultado do Agente 4 (Analisador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ```\n> **Análise de Veracidade sobre test**\n> *Data da Análise: 17/05/2025*\n> \n> **Resumo Inicial:** Enganosa/Parcial. A informação agregada sob o tópico \"test\" é muito variada e carece de um foco central, tornando a análise complexa. As fontes são geralmente de confiabilidade média, mas a ausência de um tema unificador faz com que a informação seja apresentada de forma descontextualizada, podendo levar a interpretações enganosas.\n> \n> **Fontes Avaliadas:**\n> *   Fontes de Alta Confiabilidade Notadas: https://www.pnas.org/doi/10.1073/pnas.2016980118 (0.9), https://www.cchealth.org/get-care/medical-center-services/video-visits-with-your-doctor (0.9)\n> *   Fontes de Baixa Confiabilidade Notadas: https://www.ctbto.org/ (0.1), https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-official-music-video-for-need-a-favor-httpsyoutubep1nrboaltzu/722070149284838/ (0.1), https://www.youtube.com/watch?v=IQJL3htsDyQ (0.1), https://libguides.contracosta.edu/auser (0.1), https://www.pottersignal.com/training/videos (0.1), https://publichealth.jmir.org/2022/6/e34615/ (0.1)\n> \n> **Pontos Chave da Análise de Conteúdo e Comparação:**\n> *   A busca por \"test\" retorna uma variedade de resultados, desde definições de dicionário (Merriam-Webster) e ferramentas de teste de velocidade de internet (Speedtest by Ookla) até links para tratados de proibição de testes nucleares (CTBTO) e sites de prática para o teste de cidadania americana (USCIS).\n> *   A alta confiabilidade de pnas.org sugere artigos científicos, que podem ou não estar relacionados diretamente ao conceito geral de \"test\". Similarmente, o link do Departamento de Saúde da Califórnia (cchealth.org) com alta confiabilidade sugere informações sobre \"video visits\" , que pode ser um \"teste\" de um programa de telemedicina, mas a conexão não é explícita no título.\n> *   As fontes de baixa confiabilidade variam amplamente e incluem vídeos, páginas do Facebook e guias de bibliotecas.\n> *   A ausência de um tema central dificulta a comparação cruzada. Por exemplo, o Speedtest não tem relação direta com o tratado CTBT.\n> \n> **Determinação Final:**\n> Enganosa/Parcial. A informação sob o tópico \"test\" é muito diversa e desconectada, com fontes variando em qualidade e relevância. A falta de um foco claro impede uma análise coesa, e a apresentação dessas informações sem contexto adequado pode ser enganosa.\n> ```\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🤖 Executando Agente 5 (Classificação) ---\n",
            "\n",
            "--- 🤖 Executando Agente 5 (Classificação) ---\n",
            "\n",
            "--- 📝 Resultado do Agente 5 (Classificação) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Classificação: **Possível verdade**\n> \n> Resumo da Análise:\n> \n> A análise do Agente 4 parece ser precisa em sua avaliação da busca pelo termo \"test\". Os principais pontos que sustentam essa classificação como \"possível verdade\" são:\n> \n> 1.  **Diversidade e Falta de Foco:** O Agente 4 identificou corretamente a ampla gama de resultados associados à busca por \"test\". O termo é inerentemente genérico e pode se referir a testes de velocidade, testes médicos, testes nucleares, etc.\n> \n> 2.  **Qualidade Variável das Fontes:** A análise distingue claramente entre fontes de alta e baixa confiabilidade, e a lista fornecida parece razoável. É plausível que pnas.org e cchealth.org sejam fontes mais confiáveis do que páginas do Facebook ou vídeos aleatórios no YouTube.\n> \n> 3.  **Desconexão entre as Fontes:** O Agente 4 destaca corretamente que as fontes não estão relacionadas entre si, o que dificulta a criação de uma narrativa coesa. Isso é inerente à natureza da busca por um termo tão amplo.\n> \n> 4.  **Conclusão Justificada:** A determinação final de que a informação é \"Enganosa/Parcial\" é razoável, dado o contexto. Não é que as informações individuais sejam falsas, mas sim que a apresentação de resultados tão díspares sem contexto pode levar a interpretações errôneas.\n> \n> Não há sinais óbvios de linguagem tendenciosa, sensacionalista ou afirmações exageradas na análise do Agente 4. Também não há indícios claros de que a análise tenha sido gerada por IA de forma a comprometer a avaliação. Portanto, a classificação mais adequada é \"possível verdade\". É importante notar que a análise não afirma que as informações são falsas, mas sim que a agregação e apresentação delas podem ser enganosas devido à falta de um tema unificador.\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🤖 Executando Agente 6 (Verificador Final) ---\n",
            "\n",
            "Performing additional searches for keywords: extracted keywords from classification...\n",
            "Additional search results obtained.\n",
            "\n",
            "Sending to Agente 6 for final verification...\n",
            "\n",
            "--- 📝 Resultado do Agente 6 (Verificador Final) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## Relatório de Verificação de Fatos\n> \n> **Assunto:** Análise da busca pelo termo \"test\" e sua classificação como \"Possível verdade\" pelo Agente 5.\n> \n> **Data:** 17 de maio de 2025\n> \n> **Metodologia:**\n> \n> 1.  Análise do resumo fornecido pelo Agente 5.\n> 2.  Análise dos resultados de buscas adicionais sobre \"Keyword extraction from text classification\".\n> 3.  Comparação e análise das informações para determinar a veracidade, falsidade ou exagero da informação original.\n> \n> **Análise:**\n> \n> O Agente 5 classificou a informação relacionada à busca pelo termo \"test\" como \"Possível verdade\", justificando que a diversidade de resultados e a falta de foco tornam a apresentação dos resultados potencialmente enganosa. A análise também ressalta a variabilidade na qualidade das fontes e a desconexão entre elas.\n> \n> Os resultados das buscas adicionais focaram em \"Keyword extraction from text classification\", que à primeira vista pode parecer não relacionado. No entanto, a análise do Agente 4 (mencionada no resumo do Agente 5) identificou a \"diversidade e falta de foco\" como um problema na busca pelo termo \"test\". A técnica de extração de palavras-chave (keyword extraction) é uma ferramenta útil para lidar com essa diversidade, pois permite identificar os termos mais relevantes em um conjunto de dados e classificá-los.\n> \n> A busca adicional revelou que a extração de palavras-chave é amplamente utilizada em diversas aplicações, como:\n> \n> *   **Indexação de documentos:** Facilita a busca e recuperação de informações.\n> *   **Sumarização de documentos:** Ajuda os usuários a entender rapidamente o conteúdo.\n> *   **Otimização para mecanismos de busca (SEO):** Melhora a visibilidade de conteúdos online.\n> \n> As técnicas e ferramentas mencionadas (TF-IDF, RAKE, BERT, LIME, etc.) são válidas e amplamente utilizadas no campo do processamento de linguagem natural (NLP).\n> \n> **Conclusão:**\n> \n> A classificação inicial do Agente 5 como \"Possível verdade\" parece apropriada. A busca pelo termo \"test\" é inerentemente ambígua e pode gerar resultados díspares. A análise do Agente 4 identifica corretamente esse problema.\n> \n> Os resultados das buscas adicionais sobre \"Keyword extraction from text classification\" fornecem um contexto útil para lidar com a diversidade de resultados associados à busca por \"test\". Embora a extração de palavras-chave não seja diretamente mencionada na análise inicial, ela representa uma técnica relevante para organizar e interpretar os resultados da busca.\n> \n> Portanto, a informação não é falsa, mas a apresentação dos resultados da busca por \"test\" sem um contexto adequado pode ser enganosa, como apontado pelo Agente 5. A análise da extração de palavras-chave complementa a avaliação inicial, oferecendo uma solução potencial para o problema da diversidade e falta de foco.\n> \n> **Classificação Final:** Verdadeira, com ressalvas. A informação é verdadeira, mas requer contexto adicional para evitar interpretações errôneas.\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🤖 Executando Agente 7 (Avaliador de Perguntas) ---\n",
            "Calling agent: agente_avaliador_de_perguntas with input: Relatório: ```\n",
            "**Análise de Veracidade sobre test**\n",
            "*Data da Análise: 17/05/2025*\n",
            "\n",
            "**Resumo Inicial:** Enganosa/Parcial. A informação agregada sob o tópico \"test\" é muito variada e carece de um foco central, tornando a análise complexa. As fontes são geralmente de confiabilidade média, mas a ausência de um tema unificador faz com que a informação seja apresentada de forma descontextualizada, podendo levar a interpretações enganosas.\n",
            "\n",
            "**Fontes Avaliadas:**\n",
            "*   Fontes de Alta Confiabilidade Notadas: https://www.pnas.org/doi/10.1073/pnas.2016980118 (0.9), https://www.cchealth.org/get-care/medical-center-services/video-visits-with-your-doctor (0.9)\n",
            "*   Fontes de Baixa Confiabilidade Notadas: https://www.ctbto.org/ (0.1), https://www.facebook.com/TheRealJellyRoll/posts/check-out-the-official-music-video-for-need-a-favor-httpsyoutubep1nrboaltzu/722070149284838/ (0.1), https://www.youtube.com/watch?v=IQJL3htsDyQ (0.1), https://libguides.contracosta.edu/auser (0.1), https://www.pottersignal.com/training/videos (0.1), https://publichealth.jmir.org/2022/6/e34615/ (0.1)\n",
            "\n",
            "**Pontos Chave da Análise de Conteúdo e Comparação:**\n",
            "*   A busca por \"test\" retorna uma variedade de resultados, desde definições de dicionário (Merriam-Webster) e ferramentas de teste de velocidade de internet (Speedtest by Ookla) até links para tratados de proibição de testes nucleares (CTBTO) e sites de prática para o teste de cidadania americana (USCIS).\n",
            "*   A alta confiabilidade de pnas.org sugere artigos científicos, que podem ou não estar relacionados diretamente ao conceito geral de \"test\". Similarmente, o link do Departamento de Saúde da Califórnia (cchealth.org) com alta confiabilidade sugere informações sobre \"video visits\" , que pode ser um \"teste\" de um programa de telemedicina, mas a conexão não é explícita no título.\n",
            "*   As fontes de baixa confiabilidade variam amplamente e incluem vídeos, páginas do Facebook e guias de bibliotecas.\n",
            "*   A ausência de um tema central dificulta a comparação cruzada. Por exemplo, o Speedtest não tem relação direta com o tratado CTBT.\n",
            "\n",
            "**Determinação Final:**\n",
            "Enganosa/Parcial. A informação sob o tópico \"test\" é muito diversa e desconectada, com fontes variando em qualidade e relevância. A falta de um foco claro impede uma análise coesa, e a apresentação dessas informações sem contexto adequado pode ser enganosa.\n",
            "```\n",
            "\n",
            "Pergunta: test\n",
            "Data: 17/05/2025\n",
            "Determine se a pergunta é relevante para verificar a veracidade.\n",
            "\n",
            "--- 📝 Resultado do Agente 7 (Avaliador de Perguntas) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> A pergunta é relevante para a verificação."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🤖 Executando Agente 8 (Detalhamento Final) ---\n",
            "Calling agent: agente_detalhamento_final with input: Relatório final: ## Relatório de Verificação de Fatos\n",
            "\n",
            "**Assunto:** Análise da busca pelo termo \"test\" e sua classificação como \"Possível verdade\" pelo Agente 5.\n",
            "\n",
            "**Data:** 17 de maio de 2025\n",
            "\n",
            "**Metodologia:**\n",
            "\n",
            "1.  Análise do resumo fornecido pelo Agente 5.\n",
            "2.  Análise dos resultados de buscas adicionais sobre \"Keyword extraction from text classification\".\n",
            "3.  Comparação e análise das informações para determinar a veracidade, falsidade ou exagero da informação original.\n",
            "\n",
            "**Análise:**\n",
            "\n",
            "O Agente 5 classificou a informação relacionada à busca pelo termo \"test\" como \"Possível verdade\", justificando que a diversidade de resultados e a falta de foco tornam a apresentação dos resultados potencialmente enganosa. A análise também ressalta a variabilidade na qualidade das fontes e a desconexão entre elas.\n",
            "\n",
            "Os resultados das buscas adicionais focaram em \"Keyword extraction from text classification\", que à primeira vista pode parecer não relacionado. No entanto, a análise do Agente 4 (mencionada no resumo do Agente 5) identificou a \"diversidade e falta de foco\" como um problema na busca pelo termo \"test\". A técnica de extração de palavras-chave (keyword extraction) é uma ferramenta útil para lidar com essa diversidade, pois permite identificar os termos mais relevantes em um conjunto de dados e classificá-los.\n",
            "\n",
            "A busca adicional revelou que a extração de palavras-chave é amplamente utilizada em diversas aplicações, como:\n",
            "\n",
            "*   **Indexação de documentos:** Facilita a busca e recuperação de informações.\n",
            "*   **Sumarização de documentos:** Ajuda os usuários a entender rapidamente o conteúdo.\n",
            "*   **Otimização para mecanismos de busca (SEO):** Melhora a visibilidade de conteúdos online.\n",
            "\n",
            "As técnicas e ferramentas mencionadas (TF-IDF, RAKE, BERT, LIME, etc.) são válidas e amplamente utilizadas no campo do processamento de linguagem natural (NLP).\n",
            "\n",
            "**Conclusão:**\n",
            "\n",
            "A classificação inicial do Agente 5 como \"Possível verdade\" parece apropriada. A busca pelo termo \"test\" é inerentemente ambígua e pode gerar resultados díspares. A análise do Agente 4 identifica corretamente esse problema.\n",
            "\n",
            "Os resultados das buscas adicionais sobre \"Keyword extraction from text classification\" fornecem um contexto útil para lidar com a diversidade de resultados associados à busca por \"test\". Embora a extração de palavras-chave não seja diretamente mencionada na análise inicial, ela representa uma técnica relevante para organizar e interpretar os resultados da busca.\n",
            "\n",
            "Portanto, a informação não é falsa, mas a apresentação dos resultados da busca por \"test\" sem um contexto adequado pode ser enganosa, como apontado pelo Agente 5. A análise da extração de palavras-chave complementa a avaliação inicial, oferecendo uma solução potencial para o problema da diversidade e falta de foco.\n",
            "\n",
            "**Classificação Final:** Verdadeira, com ressalvas. A informação é verdadeira, mas requer contexto adicional para evitar interpretações errôneas.\n",
            "\n",
            "\n",
            "Pergunta: test\n",
            "Data: 17/05/2025\n",
            "Analise e detalhe as informações.\n",
            "\n",
            "--- 📝 Resultado do Sistema (Relatório Final Detalhado) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> EXAGERADO: O relatório final sugere exagero no conteúdo."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎉 Sistema de Análise de Fake News Concluído! 🎉\n"
          ]
        }
      ]
    }
  ]
}